<!doctype html>
<html lang="en">
<head>
<title>Soccer Foul Detection Based on CNN and Spatial Attention</title>
<meta property="og:title" content="Soccer Foul Detection Based on CNN and Spatial Attention" />
<meta name="twitter:title" content="Soccer Foul Detection Based on CNN and Spatial Attentione" />
<meta name="description" content="Soccer Foul Detection Based on CNN and Spatial Attention" />
<meta property="og:description" content="Soccer Foul Detection Based on CNN and Spatial Attention" />
<meta name="twitter:description" content="Soccer Foul Detection Based on CNN and Spatial Attention" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Soccer Foul Detection Based on CNN and Spatial Attention </nobr>
 <nobr class="widenobr">For DS 4440</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of Automatic Soccer Video Event Detection Based on a Deep Neural Network Combined CNN and RNN</h2>
<p>Can we use only CNN to detect the fouls in a football matches?</p>
</div>
</div>
<div class="row">
<div class="col">

<body>
    <div class="container">
        <div class="row">
            <div class="col-12">
                <h1 class="text-center my-4">Soccer Fouls Detection Based on CNN and Spatial Attention</h1>
                <h3>Introduction</h2>
                <p>In recent years, the field of sports video analysis has seen significant advancements, particularly with the integration of deep learning techniques to automate the detection of specific events within game footage. Building on the foundation laid by the research paper "Automatic Soccer Video Event Detection Based on a Deep Neural Network Combined CNN and RNN," our project seeks to explore, reduce and incorporate the application of the proposed deep learning model to a new method. Specifically, our aim is to determine the effectiveness of the Convolutional Neural Network (CNN) approach when applied to distinguishing between foul and no-foul scenarios in soccer matches using screenshots/frames of soccer videos.</p>
                <h3>Review of the Source Paper</h2>
                <p>The paper "Automatic Soccer Video Event Detection Based on a Deep Neural Network Combined CNN and RNN" by Jiang et al. introduces an innovative approach to soccer video analysis by employing a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This model is tailored to detect specific events such as goals, attempts, corners, and cards by extracting semantic features from video frames using the CNN and processing these features over time with the RNN to associate them with distinct event types.</p>
                <div class="text-center">
                    <img src="https://github.com/Marco6666662/DS4440_Final_Project/blob/main/image%20(1).png?raw=true" alt="Model Structure Comparison" class="img-fluid">
                </div>
                <h3>Our Thoughts on the Paper</h3>
                <p><strong>RNN is not needed:</strong> From our perspective, Foul is less time-sensitive and space-sensitive compared to other types of soccer events. A foul might happen any time, anywhere, and is observable in a short period.</p>
                <p><strong>Needs more data:</strong> The paper only uses 16 samples for Card class. It is not convincing with such a data size. We should find a much larger data set to test the performance of CNN.</p>
                <p><strong>Add new technique to model:</strong> We could add layers to the model to boost robustness. For instance, we could add a spatial attention layer after the last convolutional layer to ensure our model focusing on more important areas of the input. In addition, we need to use GradCam (Gradient-weighted Class Activation Mapping) to see where the model is looking at.</p>
                <h3>Project Objective</h2>
                <p>The main objective of our project is to reduce the complexity of the deep neural network model provided in the aforementioned paper, and incorporate the reduced model with new techniques to form a new method. Ultimately, we aim to develop a model that can accurately predict 'foul' or 'no foul' plays in soccer matches given frames from soccer match videos. This involves:</p>
                <ul>
                    <li>Performing model compression on the existing model architecture by removing unnecessary layers, while ensuring the resulting model still fits our task.</li>
                    <li>Creating a labeled dataset that categorizes screenshots into 'foul' and 'no-foul' from various soccer matches.</li>
                    <li>Training the new model(s) on this dataset to learn and predict these two categories effectively.</li>
                </ul>
                <h3>Report of Findings</h2>
                <p>We employed stochastic gradient descent (SGD) as our optimizer, with a learning rate of 0.001 and a momentum of 0.9, and selected CrossEntropy as our loss function. 
                    This configuration aligns with the setup described in the referenced paper. The sole deviation from the paper's methodology lies in the duration of the training period: 
                    while the paper extends the training to 300 epochs, we limited ours to 50 epochs to mitigate the risk of overfitting. The images below depict the performance of both the 
                    normal and attention models on the train/test datasets. We observed that the normal(standard) model achieved a 97% accuracy on the training dataset and 83% on the test 
                    dataset. In comparison, the attention model recorded 93% accuracy on the training set and 80% on the test set, indicating that the normal model outperforms the attention 
                    model on both datasets. This observation leads us to our initial hypothesis: incorporating a spatial attention layer may potentially degrade the model's performance.
                </p>
                <div class="text-center">
                    <img src="https://github.com/Marco6666662/DS4440_Final_Project/blob/main/1713755768033.jpg?raw=true" alt="Model Performance" class="img-fluid">
                </div>
                <p>To assess our model's robustness with data not included in our primary train/test sets, we procured three recent or characteristic soccer foul videos from YouTube. 
                    The first video showcases an incident involving Pepe during a match between Real Madrid and Barcelona in the 2011-2012 season. In the footage, Pepe attempts an aerial 
                    challenge against Dani Alves, but his right foot collides with Alves' left knee, causing Alves to collapse to the pitch in evident agony. The referee immediately issued
                    Pepe a red card, signifying his expulsion from the match. We fed the videos into our model and subsequently selected one of the most illustrative frames. Displayed below
                    are the predictions generated by both the normal and the attention models. These predictions are accompanied by gradient maps, which highlight the specific regions of the
                    image that each model focuses on during analysis. From the results, it is evident that the normal model classifies the frame as a non-foul incident, whereas the attention
                    model identifies it as a foul. This is intriguing because the normal model, which previously demonstrated higher accuracy on train/test data, would ostensibly provide a more
                    dependable prediction. However, the gradient maps suggest a different narrative. The normal model predominantly focuses on Pepe's left arm and left foot with minimal attention
                     to the ball. In contrast, the attention model concentrates on the critical points of contact, including Pepe's right leg, the ball, and Alves's legs. This instance underscores 
                     the attention model's capability to target more pertinent regions of the image, thereby enhancing its predictive accuracy in complex scenarios.
                </p>
                <div class="text-center">
                    <img src="https://github.com/Marco6666662/DS4440_Final_Project/blob/main/1713754995081.jpg?raw=true" alt="Result Comparison On Pepe's foul" class="img-fluid">
                </div>
                <p>
                    The second video dates back to last December during a World Cup qualifier in Buenos Aires, where Argentina faced Uruguay. At the 20-minute mark, a tense verbal exchange erupted
                    between Uruguay's defender Mathias Olivera and Argentina's midfielder Rodrigo De Paul. Initially confined to verbal sparring, the situation escalated when Argentina's captain, 
                    Lionel Messi, intervened, turning the altercation physical. Messi initiated contact by thrusting his right elbow into Olivera's chest, followed by a brief encirclement of the 
                    Uruguayan's neck with his left hand. This video was also processed by our models, yielding consistent results: the normal model identified no foul, while the attention model 
                    detected a foul. Drawing from insights gained in the first example, an examination of the gradient maps reveals significant differences in focus areas. The normal model primarily 
                    concentrates on less relevant elements such as the players' hair and the grass in the background. In contrast, the attention model zeroes in on more critical interactions, specifically 
                    Olivera's upper body, and accurately captures Messi's hand around Olivera's neck. This instance further demonstrates the attention model's superior capability to discern pivotal components 
                    of the image, thereby providing a more explanatory and relevant analysis.
                </p>
                <div class="text-center">
                    <img src="https://github.com/Marco6666662/DS4440_Final_Project/blob/main/1713753268440.jpg?raw=true" alt="Model Structure Comparison" class="img-fluid">
                </div>
                <h3>Conclusion & Future Work</h2>
                <p>As we look toward the future, several areas have emerged as key focal points for ongoing research and development:</p>
                <ul>
                    <li>
                        <h3>Attention Model Refinement</h3>
                        <p>While the standard model exhibited higher accuracy, the attention model proved to be more sensible by utilizing more relevant evidence, as indicated by GradMap analysis. This suggests a promising avenue for enhancing the sophistication of deep neural networks in foul prediction.</p>
                    </li>
                    <li>
                        <h3>Data Diversity</h3>
                        <p>Expanding the dataset size was a step forward, yet an oversight in ensuring equitable distribution of multi-view data points highlights the importance of diversity in training datasets.</p>
                    </li>
                    <li>
                        <h3>Contextual Analysis</h3>
                        <p>Predicting frames in isolation may introduce bias. To mitigate this, we consider the integration of contextual sequences (e.g., live action, replays) for more accurate and reliable predictions, drawing inspiration from methodologies that assess combinations of actions within a game.</p>
                    </li>
                </ul>
            </div>
        </div>
    </div>

<h3>References</h3>

<p>
    <a name="jiang-2016">[2]</a>
    <a href="https://ieeexplore.ieee.org/document/7814641">
        Jiang, H., Lu, Y., & Xue, J. (2016). Automatic Soccer Video Event Detection Based on a Deep Neural Network Combined CNN and RNN.
    </a> 
    2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI). IEEE.
</p>

<h2>Team Members</h2>
                                                   
<p>Xi Chen
</p>
</p>
Qixiang Jiang
</p>

  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
